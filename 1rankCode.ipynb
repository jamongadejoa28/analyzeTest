{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896dabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost==1.2.8\n",
    "!pip install optuna==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb87550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost\n",
    "import sklearn\n",
    "import optuna\n",
    "\n",
    "versions = {\n",
    "    \"pandas\": pd.__version__,\n",
    "    \"numpy\": np.__version__,\n",
    "    \"catboost\": catboost.__version__,\n",
    "    \"sklearn\": sklearn.__version__,\n",
    "    \"optuna\": optuna.__version__,\n",
    "}\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf25f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt\n",
    "# 파일 정리에는 v2-8 TPU을 사용.\n",
    "\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_folder = '/content/drive/MyDrive/base_file/'\n",
    "\n",
    "months = [\"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "\n",
    "categories = [\"회원정보\", \"신용정보\", \"승인매출정보\", \"청구입금정보\", \"잔액정보\", \"채널정보\", \"마케팅정보\", \"성과정보\"]\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "def merge_monthly_data(data_type, category):\n",
    "    merged_list = []\n",
    "\n",
    "    for month in months:\n",
    "        file_name = f\"{drive_folder}2018{month}_{data_type}_{category}.parquet\"\n",
    "        try:\n",
    "            df = pd.read_parquet(file_name, engine=\"pyarrow\")\n",
    "            merged_list.append(df)\n",
    "            print(f\"✅ {file_name} 변환 완료\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"⚠️ 파일 없음: {file_name}\")\n",
    "\n",
    "    if merged_list:\n",
    "        merged_df = pd.concat(merged_list, ignore_index=True)\n",
    "        output_file = f\"{drive_folder}{data_type}_{category}.csv\"\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"✅ {output_file} 저장 완료 (Shape: {merged_df.shape})\")\n",
    "    else:\n",
    "        print(f\"❌ {data_type}_{category} 데이터 없음\")\n",
    "\n",
    "for data_type in data_types:\n",
    "    for category in categories:\n",
    "        merge_monthly_data(data_type, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/content/drive/MyDrive/base_file/\"\n",
    "\n",
    "file_names = [\n",
    "    \"train_회원정보.csv\",\n",
    "    \"train_신용정보.csv\",\n",
    "    \"train_승인매출정보.csv\",\n",
    "    \"train_청구입금정보.csv\",\n",
    "    \"train_잔액정보.csv\",\n",
    "    \"train_채널정보.csv\",\n",
    "    \"train_마케팅정보.csv\",\n",
    "    \"train_성과정보.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(base_path + file_names[0])\n",
    "\n",
    "for idx, file in enumerate(file_names[1:], start=2):\n",
    "    print(f\"\\n🔹 병합 중: {file} ({idx}/{len(file_names)})\")\n",
    "    temp_df = pd.read_csv(base_path + file)\n",
    "\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"기준년월\"])\n",
    "    print(f\"✅ 병합 후 크기: {df.shape}\")\n",
    "\n",
    "output_file = base_path + \"base_train.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ 최종 데이터 저장 완료: {output_file}\")\n",
    "print(f\"🧾 최종 데이터 크기: {df.shape[0]}행, {df.shape[1]}열\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/content/drive/MyDrive/base_file/\"\n",
    "\n",
    "file_names = [\n",
    "    \"test_회원정보.csv\",\n",
    "    \"test_신용정보.csv\",\n",
    "    \"test_승인매출정보.csv\",\n",
    "    \"test_청구입금정보.csv\",\n",
    "    \"test_잔액정보.csv\",\n",
    "    \"test_채널정보.csv\",\n",
    "    \"test_마케팅정보.csv\",\n",
    "    \"test_성과정보.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(base_path + file_names[0])\n",
    "\n",
    "for idx, file in enumerate(file_names[1:], start=2):\n",
    "    print(f\"\\n🔹 병합 중: {file} ({idx}/{len(file_names)})\")\n",
    "    temp_df = pd.read_csv(base_path + file)\n",
    "\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"기준년월\"])\n",
    "    print(f\"✅ 병합 후 크기: {df.shape}\")\n",
    "\n",
    "output_file = base_path + \"base_test.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ 최종 데이터 저장 완료: {output_file}\")\n",
    "print(f\"🧾 최종 데이터 크기: {df.shape[0]}행, {df.shape[1]}열\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/content/drive/MyDrive/base_file/\"\n",
    "\n",
    "file_names = [\n",
    "    \"train_회원정보.csv\",\n",
    "    \"train_신용정보.csv\",\n",
    "    \"train_승인매출정보.csv\",\n",
    "    \"train_청구입금정보.csv\",\n",
    "    \"train_잔액정보.csv\",\n",
    "    \"train_채널정보.csv\",\n",
    "    \"train_마케팅정보.csv\",\n",
    "    \"train_성과정보.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(base_path + file_names[0])\n",
    "\n",
    "original_shape = df.shape\n",
    "\n",
    "for idx, file in enumerate(file_names[1:], start=2):\n",
    "    print(f\"\\n🔹 병합 진행 중: {file} (파일 {idx} / {len(file_names)})\")\n",
    "\n",
    "    temp_df = pd.read_csv(base_path + file)\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"기준년월\"])\n",
    "    print(f\"✅ 병합 후 데이터 크기: {df.shape[0]}행, {df.shape[1]}열\")\n",
    "\n",
    "    constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    if constant_cols:\n",
    "        print(f\"📌 제거된 모든 값이 동일한 칼럼: {constant_cols}\")\n",
    "        df = df.drop(columns=constant_cols)\n",
    "    else:\n",
    "        print(\"📌 모든 값이 동일한 칼럼 없음\")\n",
    "\n",
    "    col_groups = {}\n",
    "    for col in df.columns:\n",
    "        for key in col_groups:\n",
    "            if df[col].equals(df[key]):\n",
    "                col_groups[key].append(col)\n",
    "                break\n",
    "        else:\n",
    "            col_groups[col] = [col]\n",
    "\n",
    "    duplicate_cols = [col for group in col_groups.values() for col in group[1:]]\n",
    "    if duplicate_cols:\n",
    "        print(f\"📌 제거된 중복 칼럼: {duplicate_cols}\")\n",
    "        df = df.drop(columns=duplicate_cols)\n",
    "    else:\n",
    "        print(\"📌 중복 칼럼 없음\")\n",
    "\n",
    "    if 'ID' in df.columns and df.columns.str.contains('ID').sum() > 1:\n",
    "        df = df.loc[:, ~df.columns.str.contains('ID', case=False)].join(df[['ID']])\n",
    "\n",
    "    if '기준년월' in df.columns and df.columns.str.contains('기준년월').sum() > 1:\n",
    "        df = df.loc[:, ~df.columns.str.contains('기준년월', case=False)].join(df[['기준년월']])\n",
    "\n",
    "    print(f\"🔹 {file} 처리 완료. 현재 데이터 크기: {df.shape[0]}행, {df.shape[1]}열\")\n",
    "\n",
    "new_shape = df.shape\n",
    "\n",
    "output_file = base_path + \"base_clean_train.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ 원래 데이터 크기: {original_shape[0]}행, {original_shape[1]}열\")\n",
    "print(f\"✅ 병합 후 최종 데이터 크기: {new_shape[0]}행, {new_shape[1]}열\")\n",
    "\n",
    "print(f\"\\n✅ 최종 데이터 저장 완료: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/content/drive/MyDrive/base_file/\"\n",
    "\n",
    "test_file_names = [\n",
    "    \"test_회원정보.csv\",\n",
    "    \"test_신용정보.csv\",\n",
    "    \"test_승인매출정보.csv\",\n",
    "    \"test_청구입금정보.csv\",\n",
    "    \"test_잔액정보.csv\",\n",
    "    \"test_채널정보.csv\",\n",
    "    \"test_마케팅정보.csv\",\n",
    "    \"test_성과정보.csv\"\n",
    "]\n",
    "\n",
    "test_df = pd.read_csv(base_path + test_file_names[0])\n",
    "\n",
    "test_original_shape = test_df.shape\n",
    "for idx, file in enumerate(test_file_names[1:], start=2):\n",
    "    print(f\"\\n🔹 병합 진행 중: {file} (파일 {idx} / {len(test_file_names)})\")\n",
    "    temp_df = pd.read_csv(base_path + file)\n",
    "    test_df = test_df.merge(temp_df, how=\"left\", on=[\"ID\", \"기준년월\"])\n",
    "    print(f\"✅ 병합 후 데이터 크기: {test_df.shape[0]}행, {test_df.shape[1]}열\")\n",
    "\n",
    "train_df = pd.read_csv(base_path + \"base_clean_train.csv\", nrows=1)\n",
    "train_columns = train_df.columns\n",
    "test_columns_to_keep = [col for col in test_df.columns if col in train_columns]\n",
    "\n",
    "test_df = test_df[test_columns_to_keep]\n",
    "test_final_shape = test_df.shape\n",
    "\n",
    "test_output_file = base_path + \"base_clean_test.csv\"\n",
    "test_df.to_csv(test_output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ 원래 test 데이터 크기: {test_original_shape[0]}행, {test_original_shape[1]}열\")\n",
    "print(f\"✅ 병합 후 최종 test 데이터 크기: {test_final_shape[0]}행, {test_final_shape[1]}열\")\n",
    "print(f\"\\n✅ 최종 test 데이터 저장 완료: {test_output_file}\")\n",
    "\n",
    "train_col_set = set(train_columns)\n",
    "test_col_set = set(test_df.columns)\n",
    "\n",
    "if train_col_set == test_col_set:\n",
    "    print(\"\\n✅ train과 test의 컬럼이 완전히 일치합니다!\")\n",
    "else:\n",
    "    train_only_cols = train_col_set - test_col_set\n",
    "    test_only_cols = test_col_set - train_col_set\n",
    "\n",
    "    print(f\"\\n⚠️ train과 test의 컬럼이 다릅니다!\")\n",
    "    print(f\"🔹 train에만 있는 컬럼 ({len(train_only_cols)}개): {train_only_cols}\")\n",
    "    print(f\"🔹 test에만 있는 컬럼 ({len(test_only_cols)}개): {test_only_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d84c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE model에는 A100 GPU을 사용.\n",
    "\n",
    "!pip install catboost==1.2.8\n",
    "!pip install optuna==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aac614",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36603333",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/base_file/base_clean_train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/base_file/base_clean_test.csv')\n",
    "\n",
    "ab_ids = train[train['Segment'].isin(['A', 'B'])]['ID'].unique()\n",
    "\n",
    "train = train[~train['ID'].isin(ab_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbea0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "best_params = {\n",
    "    \"bootstrap_type\": \"Bayesian\",\n",
    "    \"learning_rate\": 0.2997682904093563,\n",
    "    \"l2_leaf_reg\": 9.214022161348987,\n",
    "    \"random_strength\": 7.342192789415524,\n",
    "    \"bagging_temperature\": 0.11417356499443036,\n",
    "    \"border_count\": 251,\n",
    "    \"iterations\": 1500,\n",
    "    \"loss_function\": \"MultiClass\",\n",
    "    \"eval_metric\": \"TotalF1\",\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"verbose\": 100,\n",
    "    \"random_seed\": 42,\n",
    "    \"depth\": 8,\n",
    "    \"class_weights\": [2, 1, 1]\n",
    "}\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"🚀 Fold {fold+1} training...\")\n",
    "\n",
    "    X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "\n",
    "    model = CatBoostClassifier(**best_params)\n",
    "    model.fit(X_train_fold, y_train_fold, cat_features=cat_features)\n",
    "\n",
    "    fold_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += fold_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=range(n_classes))\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs.drop(columns='ID').values.argmax(axis=1)\n",
    "\n",
    "segment_mapping = {0: 'C', 1: 'D', 2: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "submission = pd.DataFrame({'ID': mean_probs['ID'], 'Segment': mean_probs['Segment']})\n",
    "submission.to_csv('/content/drive/MyDrive/base_file/base_catboost_kfold.csv', index=False)\n",
    "\n",
    "print(\"✅ CatBoost + 10-Fold CV 예측 완료 및 저장 🎯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIP model에는 재현성 유지를 위해 L4 GPU 사용.\n",
    "# 파일 생성 부분 RAM 부족 문제로 v2-8 TPU 사용. L4 GPU 전환지점 따로 표시 예정.\n",
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/base_file/base_clean_train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/base_file/base_clean_test.csv')\n",
    "\n",
    "train_A = train[train['Segment'] == 'A']\n",
    "\n",
    "cols_to_check = [col for col in train.columns if col not in ['ID', 'Segment']]\n",
    "\n",
    "def is_fixed_column(df, col):\n",
    "    return df[col].nunique() == 1\n",
    "\n",
    "fixed_columns_A = {col: train_A[col].iloc[0] for col in cols_to_check if is_fixed_column(train_A, col)}\n",
    "max_column_values = fixed_columns_A.copy()\n",
    "\n",
    "fixed_cols = list(max_column_values.keys())\n",
    "\n",
    "print(f\"📦 고정된 칼럼 {len(fixed_cols)}개 제거할 예정입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_ids_train = train.copy()\n",
    "for col, value in max_column_values.items():\n",
    "    matching_ids_train = matching_ids_train[matching_ids_train[col] == value]\n",
    "\n",
    "matching_ids_train_grouped = matching_ids_train.groupby('ID').filter(lambda x: len(x) == 6)\n",
    "matching_ids_train_list = matching_ids_train_grouped['ID'].unique()\n",
    "\n",
    "matching_ids_test = test.copy()\n",
    "for col, value in max_column_values.items():\n",
    "    matching_ids_test = matching_ids_test[matching_ids_test[col] == value]\n",
    "\n",
    "matching_ids_test_grouped = matching_ids_test.groupby('ID').filter(lambda x: len(x) == 6)\n",
    "matching_ids_test_list = matching_ids_test_grouped['ID'].unique()\n",
    "\n",
    "train_filtered = train[train['ID'].isin(matching_ids_train_list)].drop(columns=fixed_cols)\n",
    "test_filtered = test[test['ID'].isin(matching_ids_test_list)].drop(columns=fixed_cols)\n",
    "\n",
    "print(f\"🚀 최종 train 데이터 shape: {train_filtered.shape}\")\n",
    "print(f\"🚀 최종 test 데이터 shape: {test_filtered.shape}\")\n",
    "\n",
    "train_filtered.to_csv('/content/drive/MyDrive/base_file/train_vips_A.csv', index=False)\n",
    "test_filtered.to_csv('/content/drive/MyDrive/base_file/test_vips_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/base_file/base_clean_train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/base_file/base_clean_test.csv')\n",
    "\n",
    "train_B = train[train['Segment'] == 'B']\n",
    "\n",
    "cols_to_check = [col for col in train.columns if col not in ['ID', 'Segment']]\n",
    "\n",
    "def is_fixed_column(df, col):\n",
    "    return df[col].nunique() == 1\n",
    "\n",
    "fixed_columns_B = {col: train_B[col].iloc[0] for col in cols_to_check if is_fixed_column(train_B, col)}\n",
    "max_column_values = fixed_columns_B.copy()\n",
    "\n",
    "fixed_cols = list(max_column_values.keys())\n",
    "\n",
    "print(f\"📦 고정된 칼럼 {len(fixed_cols)}개 제거할 예정입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e213cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_ids_train = train.copy()\n",
    "for col, value in max_column_values.items():\n",
    "    matching_ids_train = matching_ids_train[matching_ids_train[col] == value]\n",
    "\n",
    "matching_ids_train_grouped = matching_ids_train.groupby('ID').filter(lambda x: len(x) == 6)\n",
    "matching_ids_train_list = matching_ids_train_grouped['ID'].unique()\n",
    "\n",
    "matching_ids_test = test.copy()\n",
    "for col, value in max_column_values.items():\n",
    "    matching_ids_test = matching_ids_test[matching_ids_test[col] == value]\n",
    "\n",
    "matching_ids_test_grouped = matching_ids_test.groupby('ID').filter(lambda x: len(x) == 6)\n",
    "matching_ids_test_list = matching_ids_test_grouped['ID'].unique()\n",
    "\n",
    "train_filtered = train[train['ID'].isin(matching_ids_train_list)].drop(columns=fixed_cols)\n",
    "test_filtered = test[test['ID'].isin(matching_ids_test_list)].drop(columns=fixed_cols)\n",
    "\n",
    "print(f\"🚀 최종 train 데이터 shape: {train_filtered.shape}\")\n",
    "print(f\"🚀 최종 test 데이터 shape: {test_filtered.shape}\")\n",
    "\n",
    "train_filtered.to_csv('/content/drive/MyDrive/base_file/train_vips_B.csv', index=False)\n",
    "test_filtered.to_csv('/content/drive/MyDrive/base_file/test_vips_B.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034590ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 코드부터 v2-8 TPU 대신 L4 GPU 사용.\n",
    "!pip install catboost==1.2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/base_file/train_vips_A.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/base_file/test_vips_A.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'verbose': 100,\n",
    "    'random_seed': 42,\n",
    "    'task_type': 'GPU',\n",
    "    'class_weights': [20, 50, 2, 1, 1],\n",
    "}\n",
    "\n",
    "n_classes = 5\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\n🚀 단일 Model Run 시작\")\n",
    "\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"📂 Fold {fold + 1}\")\n",
    "\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        eval_set=(X_valid_fold, y_valid_fold),\n",
    "        cat_features=cat_features,\n",
    "        early_stopping_rounds=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    test_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += test_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=[0, 1, 2, 3, 4])\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs[[0, 1, 2, 3, 4]].idxmax(axis=1)\n",
    "\n",
    "segment_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "a_ids = mean_probs.loc[mean_probs['Segment'] == 'A', 'ID'].tolist()\n",
    "\n",
    "print(f\"\\n✅ A로 분류된 ID 수 = {len(a_ids)}개\")\n",
    "print(f\"🔎 A ID: {a_ids[:50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e089ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/content/drive/MyDrive/base_file/train_vips_B.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/base_file/test_vips_B.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 8,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'verbose': 100,\n",
    "    'random_seed': 42,\n",
    "    'task_type': 'GPU',\n",
    "    'class_weights': [10, 10, 1, 1, 1],\n",
    "}\n",
    "\n",
    "n_classes = 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\n🚀 단일 Model Run 시작\")\n",
    "\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"📂 Fold {fold + 1}\")\n",
    "\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        eval_set=(X_valid_fold, y_valid_fold),\n",
    "        cat_features=cat_features,\n",
    "        early_stopping_rounds=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    test_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += test_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=[0, 1, 2, 3, 4])\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs[[0, 1, 2, 3, 4]].idxmax(axis=1)\n",
    "\n",
    "segment_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "b_ids = mean_probs.loc[mean_probs['Segment'] == 'B', 'ID'].tolist()\n",
    "\n",
    "print(f\"\\n✅ B로 분류된 ID 수 = {len(b_ids)}개\")\n",
    "print(f\"🔎 B ID: {b_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b67c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv('/content/drive/MyDrive/base_file/base_catboost_kfold.csv')\n",
    "\n",
    "base_df.loc[base_df['ID'].isin(a_ids), 'Segment'] = 'A'\n",
    "base_df.loc[base_df['ID'].isin(b_ids), 'Segment'] = 'B'\n",
    "\n",
    "base_df.to_csv('/content/drive/MyDrive/base_file/final_catboost.csv', index=False)\n",
    "\n",
    "print(f\"✅ Segment가 'A'로 수정된 {len(a_ids)}개 ID 반영 완료\")\n",
    "print(f\"✅ Segment가 'B'로 수정된 {len(b_ids)}개 ID 반영 완료\")\n",
    "print(\"🎯 최종 결과 저장 완료: final_catboost.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
